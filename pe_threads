#ifndef __PE_THREADS_H__
#define __PE_THREADS_H__

#if defined(__GNUC__)
  #if __cplusplus < 201103L
    #define PE_THREAD_HAS_CPP11 0
  #else
    #define PE_THREAD_HAS_CPP11 1
  #endif
#elif defined(_MSC_VER)
  #if _MSC_VER < 1800
    #define PE_THREAD_HAS_CPP11 0
  #else
    #define PE_THREAD_HAS_CPP11 1
  #endif
#endif

#include <cstdint>
#include <cstdio>
#include <cassert>

#include <string>
#include <algorithm>
#include <functional>

#include <windows.h>
#include <process.h>

using namespace std;

typedef std::int64_t int64;

struct TaskContext
{
  int task_id;
  int worker_idx;
};

class Threads
{
enum
{
  min_thread = 1,
  max_thread = 64,
  max_pending_tasks = 1024,//1<<20,  // the actual maximum pending task is max_pending_tasks - 1
  stop_task_id = 2000000000,
};

typedef void (*worker_pointer)(int task_id);
typedef void (*worker_pointer_ext)(TaskContext ctx);
struct ThreadContext
{
  int idx;
  worker_pointer worker;
  worker_pointer_ext worker_ext;
  std::function<void (TaskContext)>* worker_function;
  Threads* host;
};

public:
Threads() : threads_count(0), thread_worker(NULL), thread_worker_ext(NULL), thread_worker_function(NULL), p(0), q(0)
{
  memset(threads_context, 0, sizeof threads_context);
}

void reset()
{
  threads_count = 0;
  thread_worker = NULL;
  thread_worker_ext = NULL;
  thread_worker_function = NULL;
  p = q = 0;
  memset(threads_context, 0, sizeof threads_context);
}

void init(worker_pointer worker, const int threads = 3, const int stack = 100*(1<<20))
{
  assert(thread_worker == NULL && thread_worker_ext == NULL && thread_worker_function == NULL);

  p = q = 0;
  InitializeCriticalSection(&request_access);
  has_request = CreateEvent(NULL, FALSE, FALSE, NULL);
  has_result = CreateEvent(NULL, FALSE, FALSE, NULL);
  threads_count = max(threads, (int)min_thread);
  threads_count = min(threads_count, (int)max_thread);
  thread_worker = worker;
  for (int i = 0; i < threads_count; ++i)
  {
    threads_context[i].idx = i;
    threads_context[i].worker = thread_worker;
    threads_context[i].worker_ext = thread_worker_ext;
    threads_context[i].worker_function = thread_worker_function;
    threads_context[i].host = this;
    threads_handle[i] = (HANDLE)_beginthreadex(NULL, max(stack, 100*(1<<20)), work_thread, (void*)&threads_context[i], 0, NULL);
  }
  start = GetTickCount();
}

void init(worker_pointer_ext worker_ext, const int threads = 3, const int stack = 100*(1<<20))
{
  assert(thread_worker == NULL && thread_worker_ext == NULL && thread_worker_function == NULL);

  p = q = 0;
  InitializeCriticalSection(&request_access);
  has_request = CreateEvent(NULL, FALSE, FALSE, NULL);
  has_result = CreateEvent(NULL, FALSE, FALSE, NULL);
  threads_count = max(threads, (int)min_thread);
  threads_count = min(threads_count, (int)max_thread);
  thread_worker_ext = worker_ext;
  for (int i = 0; i < threads_count; ++i)
  {
    threads_context[i].idx = i;
    threads_context[i].worker = thread_worker;
    threads_context[i].worker_ext = thread_worker_ext;
    threads_context[i].worker_function = thread_worker_function;
    threads_context[i].host = this;
    threads_handle[i] = (HANDLE)_beginthreadex(NULL, max(stack, 100*(1<<20)), work_thread, (void*)&threads_context[i], 0, NULL);
  }
  start = GetTickCount();
}

void init(std::function<void (TaskContext)>* worker_function, const int threads = 3, const int stack = 100*(1<<20))
{
  assert(thread_worker == NULL && thread_worker_ext == NULL && thread_worker_function == NULL);

  p = q = 0;
  InitializeCriticalSection(&request_access);
  has_request = CreateEvent(NULL, FALSE, FALSE, NULL);
  has_result = CreateEvent(NULL, FALSE, FALSE, NULL);
  threads_count = max(threads, (int)min_thread);
  threads_count = min(threads_count, (int)max_thread);
  thread_worker_function = worker_function;
  for (int i = 0; i < threads_count; ++i)
  {
    threads_context[i].idx = i;
    threads_context[i].worker = thread_worker;
    threads_context[i].worker_ext = thread_worker_ext;
    threads_context[i].worker_function = thread_worker_function;
    threads_context[i].host = this;
    threads_handle[i] = (HANDLE)_beginthreadex(NULL, max(stack, 100*(1<<20)), work_thread, (void*)&threads_context[i], 0, NULL);
  }
  start = GetTickCount();
}

void wait_for_queue(int max_request = -1)
{
  if (max_request == -1) max_request = threads_count;
  if (max_request > max_pending_tasks - 1) max_request = max_pending_tasks - 1;
  for (;;)
  {
    if (get_request_count() < max_request) break;
    WaitForSingleObject(has_result, 500);
  }
}

void add_request(const int id)
{
  EnterCriticalSection(&request_access);
  assert(q + 1 != p);
  task_que[q++] = id;
  if (q >= max_pending_tasks)
  {
    q -= max_pending_tasks;
  }
  LeaveCriticalSection(&request_access);
  SetEvent(has_request);
}

void wait_for_end()
{
  wait_for_queue();
  add_request(stop_task_id);
  WaitForMultipleObjects(threads_count, threads_handle, TRUE, INFINITE);
  for (int i = 0; i < threads_count; ++i) CloseHandle(threads_handle[i]);
  CloseHandle(has_result);
  CloseHandle(has_request);
  DeleteCriticalSection(&request_access);
  end = GetTickCount();
  fprintf(stderr, "time : %u\n", (unsigned)(end - start));
}

public:

void lock()
{
  EnterCriticalSection(&request_access);
}

void unlock()
{
  LeaveCriticalSection(&request_access);
}

// inc = 0 or 1
bool get_next_request(int& id, int inc)
{
  id = -1;
  EnterCriticalSection(&request_access);
  if (p != q)
  {
    id = task_que[p];
    if (inc > 0 && id != stop_task_id)
    {
      p += inc;
      if (p >= max_pending_tasks)
      {
        p -= max_pending_tasks;
      }
    }
  }
  LeaveCriticalSection(&request_access);
  return id != -1;
}

int get_request_count()
{
  int ret = 0;
  EnterCriticalSection(&request_access);
  ret = q - p;
  if (ret < 0)
  {
    ret += max_pending_tasks;
  }
  LeaveCriticalSection(&request_access);
  return ret;
}

void work(ThreadContext thread_context)
{
  for (;;)
  {
    int id = -1;
    if (get_next_request(id, 0) == false)
    {
      DWORD wait_result = WaitForSingleObject(has_request, INFINITE);
      if (wait_result != WAIT_OBJECT_0) continue;
    }
    if (get_next_request(id, 1) == false) continue;
    if (id == stop_task_id) {SetEvent(has_request);break;}
    if (thread_context.worker) (*thread_context.worker)(id);
    if (thread_context.worker_ext)
    {
      TaskContext ctx;
      ctx.task_id = id;
      ctx.worker_idx = thread_context.idx;
      (*thread_context.worker_ext)(ctx);
    }
    if (thread_context.worker_function)
    {
      TaskContext ctx;
      ctx.task_id = id;
      ctx.worker_idx = thread_context.idx;
      (*thread_context.worker_function)(ctx);
    }
    SetEvent(has_result);
  }
}

static unsigned int __stdcall work_thread(void* p)
{
  ThreadContext context_copy = *(ThreadContext*)p;
  context_copy.host->work(context_copy);
  return 0;
}

private:
  DWORD start, end;

private:
  int threads_count;

  HANDLE threads_handle[max_thread];
  ThreadContext threads_context[max_thread];

  HANDLE has_request;
  HANDLE has_result;
  CRITICAL_SECTION request_access;
  worker_pointer thread_worker;
  worker_pointer_ext thread_worker_ext;
  std::function<void (TaskContext)>* thread_worker_function;

  int task_que[max_pending_tasks+1], p, q;
};

enum
{
  PRIORITY_REALTIME     = REALTIME_PRIORITY_CLASS,
  PRIORITY_HIGH         = HIGH_PRIORITY_CLASS,
  PRIORITY_ABOVE_NORMAL = ABOVE_NORMAL_PRIORITY_CLASS,
  PRIORITY_NORMAL       = NORMAL_PRIORITY_CLASS,
  PRIORITY_BELOW_NORMAL = BELOW_NORMAL_PRIORITY_CLASS,
  PRIORITY_BACKGROUND   = PROCESS_MODE_BACKGROUND_BEGIN,
  PRIORITY_IDLE         = IDLE_PRIORITY_CLASS,
};

static inline void set_process_priority(int priority)
{
  ::SetPriorityClass(::GetCurrentProcess(), priority);
}

static inline void make_sure_process_singleton(const char* id)
{
  string mutex_name = "pe_mutex_prefix_";
  mutex_name += id;
  HANDLE hMutex = ::OpenMutex(MUTEX_ALL_ACCESS, FALSE, mutex_name.c_str());
  if (hMutex)
  {
    fprintf(stderr, "another process is running\n");
    ::CloseHandle(hMutex);
    exit(-1);
    return;
  }
  hMutex = ::CreateMutex(NULL, TRUE, mutex_name.c_str());
  if (::GetLastError() == ERROR_ALREADY_EXISTS)
  {
    fprintf(stderr, "another process is running\n");
    ::CloseHandle(hMutex);
    exit(-1);
    return;
  }
}

#if PE_THREAD_HAS_CPP11

#include <iostream>
#include "pe_util"

struct TaskDivision
{
  TaskDivision(int64 first = 0, int64 last = 0, int64 block_size = 1) :
    first_(first), last_(last), block_size_(block_size)
    {
      assert(block_size_ >= 1);
      const int64 cnt = last_ - first_ + 1;
      first_task_ = 1;
      last_task_ = (cnt + block_size - 1) / block_size;
    }

  ~TaskDivision()
  {
  }

  pair<int64, int64> TaskID2Range(int64 id)
  {
    assert(id >= first_task_ && id <= last_task_);

    int64 u = (id - 1) * block_size_ + first_;
    int64 v = u + block_size_ - 1;
    if (v > last_) v = last_;

    return {u, v};
  }
  int64 block_size_;
  int64 first_;
  int64 last_;
  int64 first_task_;
  int64 last_task_;
};

template<typename CONTEXT>
class MultiThreadsTask
{
public:
  MultiThreadsTask(int64 first = 0, int64 last = 0, int64 block_size = 1, const char* file_name = NULL)
    : MultiThreadsTask(TaskDivision(first, last, block_size), file_name){}

  MultiThreadsTask(TaskDivision td, const char* file_name = NULL) :
    td_(td), kv_(NULL)
    {
      if (file_name)
      {
        kv_ = new KVPersistance(file_name);
      }
    }

  ~MultiThreadsTask()
  {
    if (kv_)
    {
      delete kv_;
    }
    cerr << "result = " << result() << endl;
    context_.on_finished();
  }

  void work_on_thread(TaskContext tc)
  {
    const int64 id = tc.task_id;

    // step 1: check cache
    lock();
      bool can_skip = on_start(id);
    unlock();
    if (can_skip) return;

    // step 2: run
    auto range = td_.TaskID2Range(id);
    TimeRecorder tr;
    const int64 local_result =
      context_.work_on_range(range.first, range.second, id, tc.worker_idx);
    auto usage = tr.elapsed();

    // step 3: finish
    lock();
      on_stop(id, local_result, usage);
    unlock();
  }

  bool on_start(int64 id)
  {
    cerr << id << " begins" << endl;
    if (kv_)
    {
      auto iter = kv_->storage().find(id);
      if (iter != kv_->storage().end())
      {
        const int64 old_value = iter->second;
        return context_.handle_cached_result(id, old_value);
      }
    }
    return false;
  }

  bool on_stop(int64 id, int64 local_result, TimeDelta usage)
  {
    cerr << id << " finishes. (" << usage.format() << ")" << endl;
    cerr << "local_result = " << local_result << endl;
    if (kv_) kv_->set(id, local_result);
    context_.handle_result(id, local_result);
    cerr << "result = " << result() << endl;
    return true;
  }

  void lock(){oml_.lock();}

  void unlock(){oml_.unlock();}

  int64 result() const {return context_.result();}

  int64 operator () (int thread_count) {return run(thread_count);}

  int64 run(int thread_count)
  {
    std::function<void (TaskContext)> worker([=](TaskContext tc)
      {
        work_on_thread(tc);
      }
    );

    set_process_priority(PRIORITY_IDLE);

    oml_.init(&worker, thread_count);
    for (int64 i = td_.first_task_; i <= td_.last_task_; ++i)
    {
      oml_.wait_for_queue();
      oml_.add_request((int32_t)i);
    }
    oml_.wait_for_end();
    oml_.reset();

    return result();
  }
 
private:
TaskDivision    td_;
Threads         oml_;
KVPersistance*  kv_;

protected:
CONTEXT           context_;
};

#endif

#if 0
// example of MultiThreadsTask
class ComputeSumContext
{
public:
  ComputeSumContext() : result_(0){}

  void on_finished()
  {
    cerr << "result = " << result_ << endl;
  }

  void handle_result(int64 id, int64 result)
  {
    result_ += result;
  }

  bool handle_cached_result(int64 id, int64 result)
  {
    handle_result(id, result);
    return true;
  }

  int64 result() const
  {
    return result_;
  }

  int64 work_on_range(int64 first, int64 last, int64 id, int64 worker_idx)
  {
    int64 t = 0;
    for (int64 i = first; i <= last; ++i)
    {
      t += i;
    }
    return t;
  }
protected:
  int64 result_;
};

MultiThreadsTask<ComputeSumContext> orz(1, 1000000, 100000);
orz(8);

#endif

#if 0

/* deprecated v0
template<typename IMPL>
class MultiThreadsTask
{
public:
  MultiThreadsTask(int64 first = 0, int64 last = 0, int64 block_size = 1, const char* file_name = NULL)
    : MultiThreadsTask(TaskDivision(first, last, block_size), file_name){}

  MultiThreadsTask(TaskDivision td, const char* file_name = NULL) :
    td_(td), kv_(NULL), result_(0)
    {
      if (file_name)
      {
        kv_ = new KVPersistance(file_name);
      }
    }

  ~MultiThreadsTask()
  {
    if (kv_)
    {
      delete kv_;
    }
    cerr << "result = " << result_ << endl;
  }

  void work_on_thread(TaskContext tc)
  {
    const int64 id = tc.task_id;
    
    // step 1: check cache
    bool can_skip = false;
    lock();
    {
      int64 old_value = -1;
      bool handled = false;
      bool has_value = false;
      if (kv_ && kv_->storage().count(id))
      {
        old_value = kv_->storage()[id];
        has_value = true;
      }
      handled = static_cast<IMPL&>(*this).on_start(id, has_value, old_value);
      can_skip = has_value && handled;
    }
    unlock();
    if (can_skip) return;
    
    // step 2: run
    int64 local_result = 0;
    auto range = td_.TaskID2Range(id);
    TimeRecorder tr;
    for (int64 i = range.first; i <= range.second; ++i)
    {
      static_cast<IMPL&>(*this).work(i, local_result, tc.worker_idx);
    }
    auto usage = tr.elapsed();
    
    // step 3: finish
    lock();
      static_cast<IMPL&>(*this).on_stop(id, local_result, usage);
    unlock();
  }

  void update_result(int64 local_result)
  {
    result_ += local_result;
  }
  
  bool on_start(int64 id, bool has_value, int64 old_value)
  {
    cerr << id << " begins" << endl;
    if (has_value)
    {
      static_cast<IMPL&>(*this).update_result(old_value);
      return true;
    }
    return false;
  }

  void work(int64 input, int64& local_result, int worker_idx)
  {
    // default implementation: do nothing
  }

  bool on_stop(int64 id, int64 local_result, TimeDelta usage)
  {
    cerr << id << " finishes. (" << usage.format() << ")" << endl;
    cerr << "local_result = " << local_result << endl;
    if (kv_) kv_->set(id, local_result);
    static_cast<IMPL&>(*this).update_result(local_result);
    cerr << "result = " << result_ << endl;
    return true;
  }

  void lock(){oml_.lock();}

  void unlock(){oml_.unlock();}
  
  int64 value() const {return result_;}
  
  int64 operator () (int thread_count) {return run(thread_count);}
  
  int64 run(int thread_count)
  {
    std::function<void (TaskContext)> worker([=](TaskContext tc)
      {
        this->work_on_thread(tc);
      }
    );
    
    set_process_priority(PRIORITY_IDLE);
    
    oml_.init(&worker, thread_count);
    for (int64 i = td_.first_task_; i <= td_.last_task_; ++i)
    {
      oml_.wait_for_queue();
      oml_.add_request((int32_t)i);
    }
    oml_.wait_for_end();
    oml_.reset();
    
    return value();
  }
private:

TaskDivision    td_;
Threads         oml_;
KVPersistance*  kv_;

protected:

int64           result_;
};
// example of MultiThreadsTask
struct ComputeSum : public MultiThreadsTask<ComputeSum>
{
typedef MultiThreadsTask<ComputeSum> base;
using base::MultiThreadsTask;

bool on_start(int64 id, bool has_value, int64 old_value)
{
  return base::on_start(id, has_value, old_value);
}

bool on_stop(int64 id, int64 local_result, TimeDelta usage)
{
  return base::on_stop(id, local_result, usage);
}

void update_result(int64 local_result)
{
  result_ += local_result;
}

void work(int64 input, int64& local_result, int worker_idx)
{
  local_result += input;
}
};
*/

int64 g_result;

void ThreadsWorker(TaskContext tc, TaskDivision td, Threads& locker, KVPersistance* kv)
{
  int64 id = tc.task_id;
  auto range = td.TaskID2Range(id);
  int64 local_result = -1;

  locker.lock();
    cerr << id << " begins" << endl;
    if (kv && kv->storage().count(id)) local_result = kv->storage()[id];
  locker.unlock();

  if (local_result != -1)
  {
    locker.lock();
      g_result += local_result;
    locker.unlock();
    return;
  }

  TimeRecorder tr;
  local_result = 0;
  for (int64 i = range.first; i <= range.second; ++i)
  {
    local_result += i;
  }
  auto usage = tr.elapsed();

  locker.lock();
    cerr << id << " finishes. (" << usage.format() << ")" << endl;
    cerr << "local_result = " << local_result << endl;
    cerr << "g_result = " << g_result << endl;
    if (kv) kv->set(id, local_result);
    g_result += local_result;
  locker.unlock();
}

void ThreadsRun(int64 first, int64 last, int64 block_size, int thread_count_, const char* filename = NULL)
{
  TaskDivision td(first, last, block_size);

  KVPersistance* kv = NULL;
  if (filename)
  {
    kv = new KVPersistance(filename);
  }

  Threads oml;

  std::function<void (TaskContext)> worker([=,&oml](TaskContext tc)
    {
      ::ThreadsWorker(tc, td, oml, kv);
    }
  );

  set_process_priority(PRIORITY_IDLE);

  oml.init(&worker, thread_count_);
  for (int64 i = td.first_task_; i <= td.last_task_; ++i)
  {
    oml.wait_for_queue();
    oml.add_request((int32_t)i);
  }
  oml.wait_for_end();

  if (kv) delete kv;

  cerr << g_result << endl;
}
#endif

#endif